{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Exercise from learn.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries and Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('https://www.gutenberg.org/files/33525/33525-0.txt')\n",
    "stories = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of Stories from Tagore, by Rabindranath Tagore\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r\n",
      "with this eBook or online at www.gutenberg.org\r\n",
      "\r\n",
      "\r\n",
      "Title: Stories from Tagore\r\n",
      "\r\n",
      "Author: Rabindranath Tagore\r\n",
      "\r\n",
      "Release Date: August 24, 2010 [EBook #33525]\r\n",
      "\r\n",
      "Language: English\r\n",
      "\r\n",
      "Character set encoding: UTF-8\r\n",
      "\r\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK STORIES FROM TAGORE ***\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Produced by Audrey Longhurst, Asad Razzaki and the Online\r\n",
      "Distributed Proofreading Team at http://www.pgdp.net\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Transcriber's Note:\r\n",
      "\r\n",
      "\r\n",
      "  Variations in spelling and hyphenation have been retained as in\r\n",
      "    the original.\r\n",
      "\r\n",
      "  A few typographical errors have been corrected. A complete list\r\n",
      "    follows the text.\r\n",
      "\r\n",
      "  Words italicized in the original are surrounded by _underscores_.\r\n",
      "\r\n",
      "  Words with bold emphasis in the original are surrounded by =equals\r\n",
      "    signs=.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "             STORIES FROM TAGORE\r\n",
      "\r\n",
      "\r\n",
      "               [Illustration]\r\n",
      "\r\n",
      "            THE MACMILLAN COMPANY\r\n",
      "\r\n",
      "      NEW YORK Â· BOSTON Â· CHICAGO Â· DALLAS\r\n",
      "           ATLANTA Â· SAN FRANCISCO\r\n",
      "\r\n",
      "           MACMILLAN & CO., LIMITED\r\n",
      "\r\n",
      "          LONDON Â· BOMBAY Â· CALCUTTA\r\n",
      "                 MELBOURNE\r\n",
      "\r\n",
      "        THE MACMILLAN CO. OF CANADA, LTD.\r\n",
      "\r\n",
      "                  TORONTO\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "              Stories from Tagore\r\n",
      "\r\n",
      "\r\n",
      "                   New York\r\n",
      "             The Macmillan Company\r\n",
      "                     1918\r\n",
      "\r\n",
      "             _All rights reserved_\r\n",
      "\r\n",
      "\r\n",
      "            Copyright 1916 and 1918\r\n",
      "            BY THE MACMILLAN COMPANY\r\n",
      "\r\n",
      "  Set up and electrotyped. Published, October, 1918\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stories[:1760])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFACE\r\n",
      "\r\n",
      "\r\n",
      "Every experienced teacher must have noticed the difficulty of\r\n",
      "instructing Indian children out of books that are specially intended for\r\n",
      "use in English schools. It is not merely that the subjects are\r\n",
      "unfamiliar, but almost eve\n"
     ]
    }
   ],
   "source": [
    "print(stories[1760:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PREFACE', 'Every', 'experienced', 'teacher', 'must', 'have', 'noticed', 'the', 'difficulty', 'of', 'instructing', 'Indian', 'children', 'out', 'of', 'books', 'that', 'are', 'specially', 'intended', 'for', 'use', 'in', 'English', 'schools', 'It', 'is', 'not', 'merely', 'that', 'the', 'subjects', 'are', 'unfamiliar', 'but', 'almost', 'every', 'phrase', 'has', 'English', 'associations', 'that', 'are', 'strange', 'to', 'Indian', 'ears', 'The', 'environment', 'in', 'which', 'they', 'are', 'written', 'is', 'unknown', 'to', 'the', 'Indian', 'school', 'boy', 'and', 'his', 'mind', 'becomes', 'overburdened', 'with', 'its', 'details', 'which', 'he', 'fails', 'to', 'understand', 'He', 'cannot', 'give', 'his', 'whole', 'attention', 'to', 'the', 'language', 'and', 'thus', 'master', 'it', 'quickly', 'The', 'present', 'Indian', 'story', 'book', 'avoids', 'some', 'at', 'least', 'of', 'these', 'impediments']\n"
     ]
    }
   ],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "stories_tokens_raw = nltk.regexp_tokenize(stories[1760:], pattern)\n",
    "print(stories_tokens_raw[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preface', 'every', 'experienced', 'teacher', 'must', 'have', 'noticed', 'the', 'difficulty', 'of', 'instructing', 'indian', 'children', 'out', 'of', 'books', 'that', 'are', 'specially', 'intended', 'for', 'use', 'in', 'english', 'schools', 'it', 'is', 'not', 'merely', 'that', 'the', 'subjects', 'are', 'unfamiliar', 'but', 'almost', 'every', 'phrase', 'has', 'english', 'associations', 'that', 'are', 'strange', 'to', 'indian', 'ears', 'the', 'environment', 'in', 'which', 'they', 'are', 'written', 'is', 'unknown', 'to', 'the', 'indian', 'school', 'boy', 'and', 'his', 'mind', 'becomes', 'overburdened', 'with', 'its', 'details', 'which', 'he', 'fails', 'to', 'understand', 'he', 'cannot', 'give', 'his', 'whole', 'attention', 'to', 'the', 'language', 'and', 'thus', 'master', 'it', 'quickly', 'the', 'present', 'indian', 'story', 'book', 'avoids', 'some', 'at', 'least', 'of', 'these', 'impediments']\n"
     ]
    }
   ],
   "source": [
    "stories_tokens = [i.lower() for i in stories_tokens_raw]\n",
    "print(stories_tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sleep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining and Utilizing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preface', 'every', 'experienced', 'teacher', 'must', 'noticed', 'difficulty', 'instructing', 'indian', 'children', 'books', 'specially', 'intended', 'use', 'english', 'schools', 'merely', 'subjects', 'unfamiliar', 'almost', 'every', 'phrase', 'english', 'associations', 'strange', 'indian', 'ears', 'environment', 'written', 'unknown', 'indian', 'school', 'boy', 'mind', 'becomes', 'overburdened', 'details', 'fails', 'understand', 'cannot', 'give', 'whole', 'attention', 'language', 'thus', 'master', 'quickly', 'present', 'indian', 'story', 'book', 'avoids', 'least', 'impediments', 'surroundings', 'described', 'students', 'everyday', 'life', 'sentiments', 'characters', 'familiar', 'stories', 'simply', 'told', 'notes', 'end', 'sufficient', 'explain', 'obscure', 'passages', 'possible', 'indian', 'student', 'follow', 'pages', 'book', 'easily', 'intelligently', 'students', 'read', 'stories', 'original', 'advantage', 'knowing', 'beforehand', 'whole', 'trend', 'narrative', 'thus', 'able', 'concentrate', 'thoughts', 'english', 'language', 'proposed', 'publish', 'together', 'single', 'volume']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stories_tokens_stopped = [w for w in stories_tokens if not w in stop_words]\n",
    "print(stories_tokens_stopped[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefac everi experienc teacher must notic difficulti instruct indian children book special intend use english school mere subject unfamiliar almost everi phrase english associ strang indian ear environ written unknown indian school boy mind becom overburden detail fail understand cannot give whole attent languag thu master quickli present indian stori book avoid least impedi surround describ student everyday life sentiment charact familiar stori simpli told note end suffici explain obscur passag possibl indian student follow page book easili intellig student read stori origin advantag know beforehand whole trend narr thu abl concentr thought english languag propos publish togeth singl volum\n"
     ]
    }
   ],
   "source": [
    "example = [porter_stemmer.stem(e) for e in stories_tokens_stopped[:100]]\n",
    "print(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefac everi experienc teacher must notic difficulti instruct indian children book special intend use english school mere subject unfamiliar almost everi phrase english associ strang indian ear environ written unknown indian school boy mind becom overburden detail fail understand cannot give whole attent languag thus master quick present indian stori book avoid least impedi surround describ student everyday life sentiment charact familiar stori simpli told note end suffici explain obscur passag possibl indian student follow page book easili intellig student read stori origin advantag know beforehand whole trend narrat thus abl concentr thought english languag propos publish togeth singl volum\n"
     ]
    }
   ],
   "source": [
    "print(*[snowball_stemmer.stem(w) for w in stories_tokens_stopped[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(tag):\n",
    "\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sleep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preface', 'NN'),\n",
       " ('every', 'DT'),\n",
       " ('experienced', 'VBD'),\n",
       " ('teacher', 'NN'),\n",
       " ('must', 'MD'),\n",
       " ('noticed', 'VB'),\n",
       " ('difficulty', 'NN'),\n",
       " ('instructing', 'VBG'),\n",
       " ('indian', 'JJ'),\n",
       " ('children', 'NNS')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(stories_tokens_stopped)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sleep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmas_pos = []\n",
    "for x, y in nltk.pos_tag(stories_tokens_stopped):\n",
    "    stories_lemmas_pos.append((x, get_wordnet_pos(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can now compare the lemmatized words to the unlemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('original', 'original')\n",
      "('stories', 'story')\n",
      "('whose', 'whose')\n",
      "('english', 'english')\n",
      "('translations', 'translation')\n",
      "('given', 'give')\n",
      "('reader', 'reader')\n",
      "('versions', 'version')\n",
      "('stories', 'story')\n",
      "('different', 'different')\n",
      "('indian', 'indian')\n",
      "('vernaculars', 'vernacular')\n",
      "('already', 'already')\n",
      "('appeared', 'appear')\n",
      "('others', 'others')\n",
      "('likely', 'likely')\n",
      "('follow', 'follow')\n",
      "('two', 'two')\n",
      "('longest', 'long')\n",
      "('stories', 'story')\n",
      "('book', 'book')\n",
      "('master', 'master')\n",
      "('mashai', 'mashai')\n",
      "('son', 'son')\n",
      "('rashmani', 'rashmani')\n",
      "('reproduced', 'reproduce')\n",
      "('english', 'english')\n",
      "('first', 'first')\n",
      "('time', 'time')\n",
      "('rest', 'rest')\n",
      "('stories', 'story')\n",
      "('taken', 'take')\n",
      "('slight', 'slight')\n",
      "('revision', 'revision')\n",
      "('two', 'two')\n",
      "('english', 'english')\n",
      "('volumes', 'volume')\n",
      "('entitled', 'entitle')\n",
      "('hungry', 'hungry')\n",
      "('stones', 'stone')\n",
      "('mashi', 'mashi')\n",
      "('short', 'short')\n",
      "('paragraph', 'paragraph')\n",
      "('added', 'add')\n",
      "('original', 'original')\n",
      "('bengali', 'bengali')\n",
      "('end', 'end')\n",
      "('story', 'story')\n",
      "('called', 'call')\n",
      "('postmaster', 'postmaster')\n",
      "('unfortunately', 'unfortunately')\n",
      "('omitted', 'omit')\n",
      "('first', 'first')\n",
      "('english', 'english')\n",
      "('edition', 'edition')\n",
      "('list', 'list')\n",
      "('words', 'word')\n",
      "('studied', 'study')\n",
      "('chosen', 'chosen')\n",
      "('story', 'story')\n",
      "('order', 'order')\n",
      "('bring', 'bring')\n",
      "('notice', 'notice')\n",
      "('different', 'different')\n",
      "('types', 'type')\n",
      "('english', 'english')\n",
      "('words', 'word')\n",
      "('lists', 'list')\n",
      "('sense', 'sense')\n",
      "('exhaustive', 'exhaustive')\n",
      "('end', 'end')\n",
      "('view', 'view')\n",
      "('endeavour', 'endeavour')\n",
      "('create', 'create')\n",
      "('interest', 'interest')\n",
      "('indian', 'indian')\n",
      "('words', 'word')\n",
      "('history', 'history')\n",
      "('may', 'may')\n",
      "('lead', 'lead')\n",
      "('study', 'study')\n",
      "('contents', 'content')\n",
      "('page', 'page')\n",
      "('cabuliwallah', 'cabuliwallah')\n",
      "('home', 'home')\n",
      "('coming', 'come')\n",
      "('king', 'king')\n",
      "('child', 'child')\n",
      "('return', 'return')\n",
      "('master', 'master')\n",
      "('mashai', 'mashai')\n",
      "('subha', 'subha')\n",
      "('postmaster', 'postmaster')\n",
      "('castaway', 'castaway')\n",
      "('son', 'son')\n",
      "('rashmani', 'rashmani')\n",
      "('babus', 'babu')\n",
      "('nayanjore', 'nayanjore')\n",
      "('notes', 'note')\n",
      "('cabuliwallah', 'cabuliwallah')\n"
     ]
    }
   ],
   "source": [
    "meta_lemmaed = []\n",
    "for word, pos in stories_lemmas_pos:\n",
    "    meta_lemmaed.append(lemmatizer.lemmatize(word, pos=pos))\n",
    "print(*zip(stories_tokens_stopped[100:200], meta_lemmaed[100:200]), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
